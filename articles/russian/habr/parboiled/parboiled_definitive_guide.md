# Parboiled2: зачем, как и как не надо

Сегодня, в свете бурного роста популярности функциональных языков, всё чаще находят применение комбинаторы парсеров —
подход, облегчающий разбор текста простым смертным. Такие инструменты, как Parsec (Haskell) и Planck (OCaml) уже успели
хорошо себя зарекомендовать в своих экосистемах. Их удобство и востребованность в своё время подтолкнули создателя
языка Scala, Мартина Одерски, внести в стандартную библиотеку их аналог — [Scala Parser Combinators][spc]
(ныне вынесены в [scala-modules][sm]), а знание и умение пользоваться подобными инструментами — отнести к обязательным
требованиям к Scala-разработчикам [уровня A3][a3].

[spc]: ???
[sm]:  ???
[a3]:  http://www.scala-lang.org/old/node/8610.

Эта статья посвящена библиотеке [Parboiled][pb] — мощной альтернативе и возможной замене для Scala Parser Combinators.
Мы подробно рассмотрим работу с текущей версией библиотеки — Parboiled2, а также уделим внимание Parboiled1,
так как большая часть существующего кода всё ещё использует именно её. Мы затронем следующие вопросы:

 - Почему Parboiled?
 - Введение в Parboiled2 от простого к сложному.
 - Миграция с первой на вторую версию библиотеки.
 - Подводные камни Parboiled1 и Parboiled2.
 - Паттерны и best-practices™ при написании парсеров.

[pb]: ???

(Кат: Читать длиннопост про ска́лу и парсеры → )


## Введение

Parboiled — библиотека позволяющая вам с легкостью разбирать (парсить) языки разметки (такие как HTML, XML или JSON),
конфигурационные файлы, логи, языки программирования, текстовые протоколы и вообще что угодно текстовое. Например, она
придётся весьма кстати, если вы хотите разработать свой предметно-ориентированный язык ([DSL][dsl]): с её помощью вы
сможете быстро получить абстрактное синтаксическое дерево и, вспомнив паттерн [интерпретатор][ip], исполнять команды
вашего доменного языка.

[ip]:  https://en.wikipedia.org/wiki/Interpreter_pattern
[dsl]: https://en.wikipedia.org/wiki/Domain-specific_language

На данный момент существует несколько версий данной библиотеки:

  - [Parboiled for Java][pbjava] — самая первая библиотека, написанная Маттиасом Доеницем (Matthias Doeniz) на Java и
    для Java, она до сих пор пользуются популярностью, хоть и находится в состоянии End of Life. Если по воле случая
    она вам досталась в наследство, или же вы сознательно начинаете проект на Java, советую рассмотреть в качестве
	альтернативы [grappa][grappa] — форк Parboiled1, который старательно поддерживается в работоспособном состоянии
	пользователем с ником [fge][fge].
  - [Parboiled for Scala] — библиотека, теперь уже более известная как Parboiled1, появилась на свет после того, как
    Маттиас проникся скалой. Он сделал Scala-фронтэнд для Parboiled, заодно забросив поддержку Java-версии. С выходом
    Parboiled2 потихонечку перестает поддерживаться и Scala-версия Parboiled1, однако не смотря на это, списывать его
	со счетов ее пока что не стоит:
      - Parboiled2 пока что не научился всем фичам Parboiled1;
      - Parboiled1 всё ещё используется гораздо шире, чем Parboiled2, поэтому если вас внезапно перебросят на
	    какой-нибудь старый Scala-проект, высок шанс столкнуться именно с ним.
  - Parboiled2 — новейшая версия библиотеки, устраняющая ряд недостатков PB1. Работает быстрее и, что самое главное,
    поддерживается разработчиками.

[pbjava]: ???
[grappa]: https://github.com/fge/grappa
[fge]:    https://github.com/fge

Я писал эту статью с упором на Parboiled2 (кстати, дальше я буду писать о нём менее в мужском роде, без слова
«библиотека»), но иногда я буду отвлекаться, чтобы рассказать об важных отличиях между первой и второй версиями.


### Основные фичи Parboiled2

  - Следует принципам [PEG](https://en.wikipedia.org/wiki/Parsing_expression_grammar).
  - Генерирует однопроходные парсеры. Отдельный лексер не требуется.
  - Используется типобезопасный DSL, являющийся подмножеством языка Scala.
  - Все возможные оптимизации выполняются на этапе компиляции.


### Почему Parboiled

  - Не нужно писать парсер голыми руками.

  - Читаемость, сравнимая с различными сортами BNF (по моему мнению даже и лучше).

  - Можно использовать всю мощь PEG и свободно разбирать рекурсивные структуры данных, в то время как регулярные
    выражения не могут этого [по определению][hier]. Да, регулярными выражениями вы не распарсите JSON или даже
    простейшее арифметическое выражение, что уж говорить о языках программирования. На StackOverflow есть
	[небезызвестная цитата в тему][paris]:

> Asking regexes to parse arbitrary HTML is like asking Paris Hilton to write an operating system.

[paris]: http://stackoverflow.com/a/1733489/1447225
[hier]:  https://en.wikipedia.org/wiki/Chomsky_hierarchy#The_hierarchy

  - Даже если вам нужно разобрать линейную структуру, Parboiled2 (при использовании должных оптимизаций) будет
    работать быстрее регулярных выражений. Пруфы находятся в следующем разделе.

  - В отличии от генераторов парсеров, таких как ANTLR, вы освобождены от мороки с раздельной генерацией кода и
    последующей его компиляцией. Весь код с Parboiled пишется на Scala, поэтому вы получаете подсветку синтаксиса
    и проверку типов из коробки, так же как и отсутствие дополнительных операций над файлами грамматик, в то время,
	как парсер, сгенерированный ANTLR, будет иметь две фазы синтаксического разбора. Правда, не несмотря на это,
	ANTLR всё равно мощнее, документированее и стабильнее, и поэтому может оказаться предпочтительнее во многих
	(*очень* нетривиальных) случаях.

  - Скаловские парсер-комбинаторы работают медленно. Очень медленно. Просто издевательски медленно. Маттиас проводил
    сравнение производительности парсеров для Jackson и JSON, написанных с помощью Parboiled, Parboiled2 и Scala Parser
    Combinators. С неутешительными результатами для последних можно ознакомиться дальше по тексту.

  - В отличие от [Language Workbenches][lwb], Parboiled — маленькая и простая в использовании библиотека. Вам не нужно
    скачивать плохо документированного тормозящего монстра и тратить драгоценные часы жизни на изматывающий поиск
    нужных менюшек и кнопочек всего-навсего для описания небольшого DSL. С другой стороны, вы не получите готовый
    текстовый редактор с подсветкой вашего DSL из коробки, вместо этого вам придется самостоятельно написать плагин
	для Vim, Emacs или вашей IDE, но это не делает Parboiled менее достойной альтернативой для разработки небольших
	предметно-ориентированных языков.

[lwb]: ???

  - Parboiled успешно зарекомендовал себя во [многих проектах][proj], в том числе и в кровавом энтерпрайзе.

[proj]: https://github.com/sirthias/parboiled/wiki/Projects-using-parboiled


## Сравнения производительности

Parboiled1 был известен своей медлительностью (во всяком случае, по отношению к парсерам, генерируемым ANTLR),
вызванной тем, что все действия по сопоставлению правил выполнялись в рантайме и компилятор не мог производить
над таким парсером каких-либо существенных оптимизаций. В Parboiled2 во главу угла поставили производительность,
в связи с чем многие вещи были переделаны на макросах, из-за чего компилятор получил свободу действий при
оптимизации, а пользователь — долгожданную производительность. Ниже мы продемонстрируем, каких неплохих
результатов добились разработчики.


### Parboiled против парсеров Json, написанных прямыми руками

Parboiled — это обобщённый инструмент для создания парсеров, а как известно, специализированный инструмент всегда
оказывается лучше обобщённого в решении своей специализированной задачи. В мире Java существует небольшое количество
парсеров Json, написанных вручную древними эльфийскими мастерами, и Александр Мыльцев (один из разработчиков
Parboiled2) проверил, насколько сильно Parboiled проигрывает в производительности этим артефактам.
[Результаты][bench-elv] оказались достаточно оптимистичными, особенно в случае с Parboiled2.

[bench-elv]: http://myltsev.name/ScalaDays2014/#/

      Тест-кейс                           │ Время, мс │ Хвост для сравнения
    ──────────────────────────────────────┼───────────┼─────────────────────────────────
      Parboiled1JsonParser                │     85.64 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
      Parboiled2JsonParser                │     13.17 │ ▇▇▇▇
      Argonaut                            │      7.01 │ ▇▇
      Json4SNative                        │      8.06 │ ▇▇
      Json4SJackson                       │      4.09 │ ▇


### Parboiled против регулярных выражений

Благодаря использованию статических оптимизация, Parboiled2 способен работать значительно быстрее регулярных выражений
(как минимум тех, что идут в комплекте с библиотекой классов Java). Вот немного подтверждающих данных
из [списка рассылки][bench-re]:

      Тест-кейс                           │ Время, мс │ 
    ──────────────────────────────────────┼───────────┼───────────────────────────────────
      Parboiled2 (warmup)                 │   1621.21 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
      Parboiled2                          │    409.16 │ ▇▇▇▇▇▇▇▇
      Parboiled2 w/ better types (warmup) │    488.92 │ ▇▇▇▇▇▇▇▇▇▇
      Parboiled2 w/ better types          │    134.68 │ ▇▇▇
      Regex (warmup)                      │    621.95 │ ▇▇▇▇▇▇▇▇▇▇▇▇
      Regex                               │    620.38 │ ▇▇▇▇▇▇▇▇▇▇▇▇

[bench-re]: https://groups.google.com/forum/#!msg/parboiled-user/XATcJRLTXjA/XSmf3n6gZSwJ


### Parboiled против Scala Parser Combinators

В списке рассылки можно найти и [другой тест производительности][bench-spc], который неплохо согласуется с первым
(про Json) и содержит данные для сравнения со Scala Parser Combinators. Всё очень и очень печально.

      Тест-кейс                           │ Время, мс │
    ──────────────────────────────────────┼───────────┼─────────────────────────────────
      Parboiled1JsonParser                |     73.81 | ▇
      Parboiled2JsonParser                |     10.49 | ▇ 
      ParserCombinators                   |   2385.78 | ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇

[bench-spc]: https://groups.google.com/forum/#!topic/parboiled-user/bGtdGvllGgU


## Новые возможности Parboiled2

Данный раздел будет, в основном, полезен и понятен тем, кто уже работал с первой версией библиотеки. Новичкам, скорее
всего, стоит вернуться к этому списку после прочтения всей статьи.

  - Parboiled2 решает ряд детских болезней первой версии:
    - Возможность использования правил более вместительных, чем `Rule7`. Для этого была использована библиотека
      [shapeless][shapeless] с ее знаменитыми `HListами`: теперь одно правило может оперировать большим количеством
	  значений на стеке.
    - Добавлены недостающие конструкции. Так, в Parboiled1 нельзя было указать динамическое количество повторений
      для правила nTimes и приходилось использовать более «мягкое» правило `oneOrMore`, что не давало нужной точности
	  при описании грамматики.
    - Добавлены встроенные примитивные терминалы. Появился новый класс `CharPredicate`, который содержит такие поля,
	  как `AlphaNumeric`, `Hex`, `Printable`, `Visible` и другие.
    - Добавлена возможность расширения и сужения предиката. Потребность исключить несколько символов из правила
      возникала и раньше, но только теперь это можно с легкостью можно сделать, а не создавать белый список символов.
  - Parboiled2 использует дополнительную зависимость — библиотеку shapeless.
  - Parboiled2 использует макросы, что позволяет генерировать грамматику на этапе компиляции, а не во время выполнения,
    как это было в Parboiled1. Это многократно увеличивает производительность вашего парсера, так же как увеличивает
    количество проверок. В связи с этим блок `rule` стал обязательным, хотя Parboiled1 позволял в некоторых случаях
	обходиться без него. Это нововведение вы заметите в первую очередь когда будете делать миграцию старого кода.
  - Улучшена система отчета об ошибках.
  - Поддержка [scala.js][scalajs]. Демо-проект можно посмотреть [здесь][scalajs-demo].
[shapeless]:    ???
[scalajs]:      ???
[scalajs-demo]: https://github.com/alexander-myltsev/parboiled2-scalajs-samples


## Как работать с библиотекой

Если вы никогда не работали с Parboiled и из предыдущих разделов не поняли, о чём вообще идёт речь, то в этом разделе
специально для вас речь пойдёт об основных правилах сопоставления символов. Все имеющиеся в PB правила в рамках этой
статьи мы рассматривать не будем — для этого есть документация, я всего лишь хочу, чтобы вы чувствовали себя уверенно
с нотацией, используемой в Parboiled.

Для закрепления знаний мы напишем простой распознаватель для несложной грамматики. Распознаватель (recognizer), а не
полноценный парсер, так как он будет только сопоставлять входной текст описанными нами правилам (также называемым
*продукциями*), но не будет извлекать из сопоставленного текста какие-либо значения. Разпознаватель может быть полезным
и сам по себе, так может работать в качестве валидатора: если вход оказался некорректным с точки зрения парсера, он
расскажет, что пошло не так и где. А совсем классным наш распознаватель станет тогда, когда мы узнаем, как извлекать
разобранные значения и причем тут какой-то «value stack». Ну что, поехали?


### Подготовительные работы

Перед началом работы с библиотекой добавим ее в classpath. В maven, например, это делается так:

    <dependency>
        <groupId>org.parboiled</groupId>
        <artifactId>parboiled_2.11</artifactId>
        <version>2.1.0</version>
    </dependency>

Значение `artifactId` недвусмысленно содержит используемую версию языка Scala, а не самого Parboiled. Я использую
Scala 2.11, однако существует соответствующий артефакт и для 2.10.

Теперь напишем парсер, который ничего не делает, что не мешает ему существовать и радоваться жизни:

    import org.parboiled2._

    class UselessParser(val input: ParserInput) extends Parser {
      // Kill me plz.
    }

Конструкции DSL, а так же ряд полезных класов добавляются в зону видимости всего одной директивой импорта.
Прошу заметить, что наличие параметра `input` в конструкторе является обязательным: это означает, что на каждого нового
набора входных данных нужно создавать новый объект-парсер. Вначале меня это очень сильно пугало, но я перестал бояться,
когда увидел, как быстро оно работает.


### Правила для отдельных символов

Итак, когда никчёмный парсер у нас уже имеется, нужно добавить с него несколько правил, в соответствии с которыми он
и будет обрабатывать данные. Если вы работали с Parboiled1, этот раздел можно просто пролистать, так как мои объяснения
могут показаться вам слишком уж подробными.

Начнем мы с терминалов. Это термин будет использоваться в дальнейшем, поэтому определим его так:

> Терминал — это правило, не требующие дополнительных определений, т.е. не использующее других нетривиальных правил.

Правила добавляют прямо внутрь класса парсера и могут использовать как друг друга, так и, при необходимости, правила из
других парсеров. Давайте опишем два простейших правила: одно из них способно распознать некоторый наперёд известный
символ, другое — строку:

    def UselessCharRule   = rule { ch('?') }
    def UselessStringRule = rule { str("hopelessness") }

Каждый раз обозначать свои намерения подобным образом весьма утомительно, но благодаря механизму неявного преобразования
(implicit conversions), можно переписать их короче:

    def UselessCharRule   = rule { 'a' }
    def UselessStringRule = rule { "hopelessness" }

Важно, что строка сопоставляется с точным учётом регистра символов. Если нет необходимости быть такими занудами, можно
использовать готовое правило `ignoreCase` (передаваемая в него строка обязательно должна быть в нижем регистре):

    def UselessStringWithCaseIgnored = rule { ignoreCase("hopelessness") }

Подробнее о правилах (или «продукциях», если вам заумные академические термины вам нравятся больше) будет рассказано
далее. Сейчас же нам необходимо знать, что `Rule0` сопоставляет вход с правилом и говорит, совпало или нет. Все
приведенные выше (и ниже) правила имеют тип `Rule0`. Мы его не указывали потому, что механизм вывода типов языка пока
легко справляется и сам. Но тип можно указать и явно:

    def UselessStringWithCaseIgnored: Rule0 = rule { ignoreCase("hopelessness") }

В Parboiled существуют два особенных терминала, которые по идее должны обрабатываться специальным образом, отличным от
простого текста (поэтому их ещё называют синтаксическими предикатами):

  - EOI (End of Input) — виртуальный символ-маркер конца ввода, котоый вы обязательно захотите добавить в главное
    правила своего парсера.
  - ANY — любой символы, кроме EOI.

Но, к сожалению, в Parboiled они определены при помощи следующего костыля:

    val EOI = '\uFFFF'

Несмотря на то, что символ U+FFFF зарезервирован для внутреннего использования стандартом Юникода, на практике он может
запросто встретиться в пользовательском вводе и изменить поведение парсера. Поэтому будьте внимательны с текстом,
который передаёте на вход.

Кроме того, если вы не добавите EOI в конец цепочки главного правила и при парсинге возникнет ошибка, то о ней вы не
узнаете, так как парсер будет считать, входные данные ещё не закончились и для него пока ещё не поздно всё исправить.
Поэтому, чтобы вы не подали на вход, на выходе вас ожидает бессмысленный Success.

Из правил `chr` и `str` вряд ли можно составить полезный парсер, поэтому первым шагом к осмысленности станет
возможность определять *диапазон* допустимых симовлов. В Parboiled2 это делается очень легко:

    def Digit      = rule { '0' - '9' }
    def AlphaLower = rule { 'a' - 'z' }

Оба эти правила сопоставят за раз максимум один символ (или не сопоставят ни одного). Хотя написать конкретно эти два
правила в PB2 очень просто, делать этого нет необходимости: они уже есть в классе `CharPredicate`, а вот Parboiled1
заставлял делать это часто, практически каждый раз, когда вы пишете очередной парсер. Поэтому я носил свою
библиотечку примитивов из проекта в проект (уверен, что не я один так делал). Теперь моя библиотечка заметно
подыстощилась благодаря появлению `CharPredicate`. В него входят, например, следующие правила (думаю, что из названий
будет понятно, каким категориям символов они соответствуют):

 - `CharPredicate.All` (работает почти так же, как `ANY`, но показывает худшую производительность на больших диапазонах
   символов);
 - `CharPredicate.Digit`;
 - `CharPredicate.Digit19`;
 - `CharPredicate.HexDigit` и много других правил.

Кроме того, для символьных предикатов работают правила `except` (`--`) и `union` (`++`), которых не было в PB1. Лично
я от этого отсутствия очень страдал: приходилось замыкать правило «с другой стороны», перечисляя полностью черный или
белый список символов в зависимости от ситуации).

    // Сопоставит любой печатный символ, если это не кавычка. И будет работать
    // медленно, так как операция вычитания из множества будет выполнять каждый
	// раз когда применяется правило. Стоит вынести определение символьного
	// предиката в отдельную константу.
    def AllButQuotes = rule { CharPredicate.Visible -- "\"" -- "'" }

    // Вполне себе сойдет для определения идентификатора. Обратите внимание, как
    // AlphaNum объединяется с нижним подчергиванием.
    def ValidIdentifier = rule {
	  CharPredicate.Alpha ~ zeroOrMore(CharPredicate.AlphaNum ++ "_") }

Полезно будет рассказать ещё о двух правилах: `anyOf` и `noneOf`. Они очень похожи на `except` и `union`, но работают
на всём пространстве символов ANY. И самое главное: в этом пространстве они работают быстрее. Эти функции могут
принимать на вход строку, состоящую из перечислений символов. Например:

    // Определит, является ли символ одной из арифметических операций.
    def AithmeticOperation = rule { anyOf("+-*/^") }

    // Сопоставит всё, кроме пробела и EOI.
    def TheCurseOf32 = rule { noneOf(" ") }

Итак, что же выбрать: `anyOf`/`noneOf` или `CharPredicate`? Заранее предопределенный символьный предикат будет работать
быстрее для 7-битных символов ASCII. «Заранее предопределенный» написано не просто так, и в разделе «Best Practices»
рассказано, почему. Однако для очень больших символьных диапазонов `CharPredicate` ведёт себя откровенно плохо, и тогда
на помощь должны прийти `anyOf` и `noneOf`.

### Цепочки правил

TODO:


#### Операция последовательности (Sequence)

Для указания того факта, что два правила должны сматчиться одно сразу за другим используется оператор `(~)`. В регулярных
выражениях нет необходимости в подобном операторе, там этот факт записывается непосредственным образом, так же, как и
в BNF. Для примера напишем (предельно упрощённое) правило для сопоставления с форматом адреса электронной почты:

    def UserName = rule { oneOrMore(CharPredicate.AlphaNum ++ "_-+.") }
    def HostName = rule { oneOrMore(CharPredicate.AlphaNum ++ "_-.")

    def ReallySimplifiedEmail = rule { UserName ~ "@" ~ HostName }

**Предупреждение:** Как и проверка регулярными выражениями, этот парсер отсечёт много легитимных электронных адресов
и пропустит много некорретных, поэтому его лучше не использовать в продакшне. С другой стороны, при помощи Parboiled
легко можно написать более продвинутый парсер, и он не будет выглядеть как вот [это регулярное выражение][re-email].

[re-email]: ???


#### N.times

Mатчить единичные символы не интересно, поэтому перейдем к более сложным правилам. Начнём с `times`, которое позволяет
сопоставить вполне определённое количество идущих подряд правил.

    def BartLearningParboiled = rule { 100 times "I will never write a parser again" }

Некоторые грамматики требуют жесткого диапазона числа повторений, например [от двух до пяти][korn]. В новом Parboiled
это можно легко устроить:

    def FutureOfCxx = rule { 'C' ~ (2 to 5) times '+' }

[korn]: http://www.chukfamily.ru/Kornei/Prosa/Ot2do5/Ot2do5.htm

А в старом — существует правило `nTimes`, которое, однако, требует указания точного числа повторений. Если же точное
значение заранее не известно, то приходилось прибегать к следующим двум правилам.


#### zeroOrMore

Внимательный читатель уже замечал это правило в примерах и оно ему, скорее всего, хорошо знакомо: в регулярных
выражениях точно такая же операция обозначается звёздочкой, а любители академической терминологии, кроме того, знают,
что она называется [звездой Клини][kstar]. В любом случае, использовать это правило очень просто:

    def Whitespace          = rule { anyOf(" \n\t") }
    def OptionalWhitespaces = rule { zeroOrMore(WhiteSpace) }

[kstar]: https://ru.wikipedia.org/wiki/%D0%97%D0%B2%D0%B5%D0%B7%D0%B4%D0%B0_%D0%9A%D0%BB%D0%B8%D0%BD%D0%B8


#### oneOrMore

Правило, похожее на предыдущее. Оно делает почти то же самое, что и `zeroOrMore`, но требует, чтобы хотя бы одно
повторение присутствовало во входных данных. Идентично плюсу Клини для регулярных грамматик.

    def UnsignedInteger = rule { oneOrMore(CharPredicate.Digit) }


#### separatedBy

Часто приходится иметь дело со случаем, когда множество элементов записываются подряд через определённый разделитель:
это CSV, и перечисление аргументов функции через запятую, и многие другое. В Parboiled2 парсинг таких
последовательностей делается легко и непринужденно:

    def CommaSeparatedNumbers rule { oneOrMore(UnsignedInteger).separatedBy(",") }

Однако, первая версия использует для этого намного менее элегантный синтаксис.


#### optional

Если бы существовало правило `zeroOrOne`, то это и был бы `optional`: либо есть одно вхождение, либо вхождений нет
совсем. Возможно, академики уже назвали соответствующий оператор регулярных выражений «вопросительным знаком Клини»,
я не знаю. Давайте разберем следующий пример: в разных семейства операционных систем маркер конца строки кодируется
по-разному. Например, в Unix-подобных операционных системах нужен только символ '\n', тогда как в Windows исторически
используется последовательность из двух симвловов: '\r' и '\n'. И если мы хотим обрабатывать текст, созданный в
любой из этих систем, то может использовать следующее правило для конца строки:

    def NewLine = rule { optional('\r') ~ '\n' }


#### (|)

Аналог оператора `|` в регулярных выражениях, неспроста называемый *упорядоченным* выбором Клини^W. Предположим, что
нам нужно распознать число, у которого может быть знак, а может и не может. Знак бывает двух типов: положительный и
отрицательный, разберемся сначала с ним:

    def Signum = rule { '+' | '-' }

Далее, знак может вовсе отсутствовать в записи положительного числа:

    def MaybeSign = rule { optional(Signum) }

А само число число тогда представится в виде последовательности из знака числа и его модуля — числа без знака:

    def SignedInteger = rule { MaybeSign ~ UnsignedInteger }

Порядок перечисления вариантов в правиле `Signum` имеет значение: выбирается самый первый из подошедших вариантов.
Это исключает возможность появление неоднозначности у вашей грамматики. И да, так работают все PEG-парсеры. Так, если
у нас стоит задача сопоставления операций языка C, начинать перечисление нужно с самых длинных, чтобы они сматчились
первыми (так предписывает стандарт). Упрощённо, правило может выглядеть, например, так:

    def COperators = rule {
      "+=" | "-=" | "*=" | "/=" | "%=" | "&=" | "^=" | "|=" | "<<=" | ">>=" |
      "<<" | ">>" | "<=" | ">=" | "==" | "!=" |
	  "||" | "&&" | "->" | "++" | "--" |
	  "<"  | ">"  | "+"  | "-"  | "&"  | "|" | "." |
	  "*"  | "/"  | "!"  | "~"  | "^"  | "=" | ","
	}

Порядок перечислений может быть самым различным, но нужно обеспечить, чтобы в нём `+` всегда шёл после `+=` и `++`,
а `<` — после `<=` и `<<` (а `<<`, в свою очередь, после `<<=`). В противном случае может случиться, что составной
оператор присваивания `<<=` распарсится в последовательность [`<=`, `=`], а то и вовсе [`<`, `<`, `=`].

Если правило выбора становится избыточно сложным и не хочется полагаться на порядок его элементов, стоит сгруппировать
их по общим префиксам (факторизовать парсер):

    def COperators = rule {
      ("+" ~ optional("=" | "+")) |
	  ("<" ~ optional("=" | ("<" ~ optional("=")))) | ...
	}

Заметим, однако, что при подобном описании парсер не сможет автоматически учитывать приоритеты операторов, для этого
придётся прибегнуть к более изощрёным правилам.


### Немного C₁₂H₂₂O₁₁

Для `optional`, `oneOrMore` и `zeroOrMore` существует синтаксический сахар, позволяющий сделать определения ещё короче:
`.?`, `.+` и `.*`. На самом деле они представляют собой простые методы с несколько необычными именами. Пожалуйста,
используйте их мудро (или хотя бы не говорите никому, что это я вам про них рассказал): если их навертеть, ваши правила
будут читаться немногим лучше, чем регулярки. Перепишем парсер знаковых чисел с использованием «сахара»:

    def UnsignedInteger = rule { CharPredicate.Digit.+ }
    def SignedInteger   = rule { (+ | -).? ~ UnsignedInteger }

И добавим поддержку массивов из целых чисел:

    def IntegerArray = rule {
      SignedInteger * (OptionalWhitespaces ~ ',' ~ OptionalWhitespaces)
	}

    // То же самое, но при этом лучше читается.
    def IntegerArray = rule {
	  zeroOrMore(SignedInteger) separatedBy (OptionalWhitespaces ~ ',' ~ OptionalWhitespaces)
	}


### Запуск парсера

Для того, чтобы заставить написанный парсер сделать хоть что-то полезное, нужно вызвать метод `run` его главного
(корневого) правила (если вы пишете юнит-тест для парсера, то может иметь смысл вызывать этот метод и для других
правил). Скобочки после метода при этом обязательны.

Давайте заставим работать наш бесполезный парсер, умеющие сопоставлять только одну строковую константу. Итак, если
наш парсер определён следующим образом (не забываем про EOI), то

    import org.parboiled2._

    class UslessParser(val input: ParserInput) extends Parser {
      def UselessStringRule: Rule0 = rule { ignoreCase("hopelessness") ~ EOI }
    }

Теперь где-нибудь в другом месте создадим два экземплляра парсеров и подадим им на вход разные данные:

    val p1 = new MyParser("Hopelessness")
    val p2 = new MyParser("Happiness")

    // по-умолчанию возвращают scala.util.Try
    p1.MyStringRule.run()
    p2.MyStringRule.run()

Прогон правил в Parboiled2 намного проще чем в Parboiled1, для которого существует целый зоопарк раннеров
(parser runners), которые приходится дополнительно вызывать. За более подробной информацией прошу в раздел
«Отчеты об ошибка».


### Вложенные структуры данных

Разбор рекурсивных структур — это как раз то, что может Parboiled и не могут регулярные выражения. В Parboiled это
получается словно само — естественно и непринужденно, что мы сейчас и продемонстрируем на последующих примерах.
Единственное дополнительное усилие которое от вас требуется — явно объявить тип правил, участвующих в рекурсии.

Разбор рекурсивных структур обычно иллюстрирую на примере калькулятора арифметических выражений. По моему мнению,
пример совершенно не нагляден. Поэтому мы рассмотрим вымышленный формат конфигурационных файлов, состоящий из
именованных блоков, содержащих пар «ключ—значение».


#### Формат BKV (Block-Key-Value)

Для определённости назовём наш вымышленный упрощённый формат аббревиатурой «BKV». Возможно, такой формат уже где-то
существует под другим именем, дайте мне знать, если это так :). BKV состоит из блоков, которые могут содержать как
пары «ключ-значение», так и другие блоки. Выглядит это примерно так:

    server {
      port = "8080"
      address = "localhost"

      settings {
        greeting_message = "Hello!\n It's me!"
      }
    }

Как видите, формат прост и незатейлив, хотя строки с экранированием (escaping) могут напугать тех, кто никогда не
писал парсеры. Экранирование очень часто встречается при синтаксическом разборе, поэтому мы обязательно и в
подробностях его рассмотрим.

Начем описание со вспомогательных элементов, а именно, с пробелов. В нашем случае пробелами будут являться символы:
' ', '\n' и '\t'. Конечно же, пробельных символов в природе существует куда больше, но в примере мы ограничимся тремя.
Разобраться с пробелами можно разными способами:

 - перечислить символы через оператор упорядоченного выбора;
 - объявить свой `CharPredicate`, содержащий эти три символа;
 - использовать `anyOf`.

Мы воспользуемся последним. При этом учтём, что в некоторых местах пробелов может быть несколько, в некоторых их может
не быть вовсе, а кое-где пробелы должны быть обязательно (но нашему формату обязательные пробелы не требуются):

    val WhitespaceChars = " \n\t"
    def Whitespace      = rule { oneOrMore(anyOf(WhitespaceChars)) }
    def OptWhitespace   = rule { zeroOrMore(anyOf(WhitespaceChars)) }

Теперь перейдём к синтаксису пары ключ–значение. Потребуем, чтобы ключ представлял собой валидный идентификатор, как
принято в большинства языков программирования: ему позволено содержать буквы английского алфавита (строчные и заглавные),
цифры, а также символ подчеркивания. Вынесем допустимые символы в отдельные предикаты и определим правило:

    val KeyChar      = CharPredicate.AlphaNum ++ '_'
    val KeyCharFirst = KeyChars -- CharPredicate.Digit

    def Key = rule { KeyCharFirst ~ zeroOrMore(KeyChar) }

Значением, в нашем случае будет любое значение кроме пробела или других символов табуляции

    // Любой символ, кроме пробела и перевода строки
    def Value = rule { oneOrMore(noneOf(WhiteSpaceChars)) }
    def KeyValuePair = rule { Key ~ OptWS ~ "=" ~ OptWS ~ Value ~ NewLine }

ПАШЕ: В доработке находится только конец главы. Начало можно черкать
TODO: Описать блок и остальные элементы структуры
TODO: Написать и закомитить распознаватель пройтись тестами.

На данном этапе мы написали простой распознаватель, исходный код которого находится [тут][bkv-gist]. Сопоставлять значения
на практике приходится весьма редко. А вот захватывать их — практически каждый раз.

[bkv-gist]: ???


## Захватывающие истории

Чтобы совершить какое-то полезное дейстие над данными, нам надо их сначала захватить. Для этого существует
функция `capture`: она сопоставляет данные с правилом и в случае успеха помещает их на стек значений.

Предположим у нас есть правило типа `Rule0`, из которого мы хотим хоть что-то вытащить:

    def User: Rule0 = rule { FirstName ~ Separator ~ LastName }

Нам нужно решить, что именно мы будем захватывать, хотя очевидно, что разделитель не представляет художественной
ценности:

    def User: Rule2[String, String] = rule {
      capture(FirstName) ~ Separator ~ capture(LastName)
	}

С этого момента наше правило уже не `Rule0`, а `Rule2`, так как оно захватывает и оправляет в стек значений две
строки. Впрочем, в нашем простом случае тип можно было и не указывать, компилятор всё поймет сам.


### Стек значений (Value Stack)

Прежде чем извлекать какие-либо данные при помощи правил, следует немного рассказать про одну из концепций,
использующихся в Parboiled. Она называется Value Stack и её можно не совсем корректно перевести как «стек значений»
(как будто кому-то нужны стеки без значений). Представляет он собой, действительно, стек, который модифицируется
*действими на парсерах* (parser actions), в него помещаются и из него извлекаются результаты парсинга правил. Именно
этому самому стеку мы должны дать подсказку при объявлении рекурсивных правил. Для того, чтобы элементы были помещены
на стек, их необходимо явно захватить, что отразится на виде ваших правил. Типы правил так же отражают количество
захваченных элементов и их тип. Элементы стека могут иметь разный тип, а типизация стека значений проверяется на
этапе компиляции.


### Типы правил

В Parboiled2 существуют следующие типы правил:

 - `Rule0` — просто отвечает на вопрос "Сопоставилось ли?", не изменяя содержимое стека.
 - `Rule1` — помещает один объект в стек значений.
 - `Rule2` — помещает два объекта в стек значений.
 - `RuleN` — помещает N объектов в стек значений, используя семантику библиотеки Shapeless. Для работы с Parboiled2
   знать Shapeless не нужно (хотя и будет полезно).
 - `PopRule` — извлекает значения со стека, не помещая туда новых значений.

При желании можно объявить свои псевдонимы для типов, как это было в Parboiled1. Например, так в коде Parboiled2
реализуется реализуется `Rule2`:

    type Rule2[+A, +B] = RuleN[A :: B :: HNil]

В Parboiled1 для каждого количества аргументов от 0 до 7 существовало по отдельному типу, что создавало так называемую
«проблему `Rule7`»: класса `Rule8` уже нет и положить восемь элементов в стек значений не получится, даже если очень
сильно хочется. Существуют различные пути для обхода этой проблемы, про один из них я расскажу далее в статье.


### Действия на парсерах (parser actions)

Действия на парсерах стоило бы назвать действиями над стеком, так как они позволяют извлекать данные из
сопоставившихся правил и преобразовывать их, а при условии высокой степени вашей испорченности — и производить с ними
сайд-эффекты (что может быть в некоторых случах действительно необходимо, например если размер и количество извлекаемых
данных заранее не известны). С помощью действий можно формировать абстрактные синтаксические деревья ([AST][ast]), их
можно использовать для вычисления «на месте», как это сделано в [примере с калькулятором](calc).

[ast]: https://en.wikipedia.org/wiki/Abstract_syntax_tree
[calc]: https://github.com/sirthias/parboiled2/blob/master/examples/src/main/scala/org/parboiled2/examples/Calculator1.scala


### Оператор действия (~>)

... или оператор, которым вам придётся пользоваться чаще всего. В качестве правого параметра принимает лямбду, на вход
которой отправляет прямо со стека захваченные объекты и тем самым позволяет лямбде с этими объектами работать. Потом,
при желании, значения можно отправить обратно в стек, или же создать из них ноду для вашего AST, выберите по своему
вкусу. В любом случае, для того чтобы действие осуществилось, нужно предватительно выполнить захват данных на стек при
помощи функции `capture`. В завимисости от типа возвращаемого значения используются различные формы оператора (~>),
что делает использование данного оператора простым и интуитивным.

**Легаси:** В Parboiled1 захват выполнялся неявно, что мне кажется весьма неудобным.

Теперь немного подробнее про лямбду. Её сигнатура зависит от количества и типизации захваченных объектов, причём за раз
лямбда может захватить [не более 22 аргументов][lambda22]. Типы аргументов лямбды соответствую типам значений, снимаемых
со стека, а типы возвращаемых значений — типам значений, помещаемых назад в стек.

[lambda22]: https://github.com/sirthias/parboiled2/issues/85

Для примера попробуем вырвать у парсера хотя бы одно целое число:

    def UnsignedInteger: Rule1[Int] = rule {
      capture(Digit.+) ~> (numStr => numStr.toInt)
	}

В этой ситуации поощряется использование фирменного скаловского плейсходера:

    def UnsignedInteger: Rule1[Int] = rule { capture(Digit.+) ~> (_.toInt) }

Здесь наша лямбда имеет тип `(String -> Int)`, что обуславливает тип нашего правила `Rule1[Int]`. Позволяется применять
оператор (~>) и к типизированному правилу, например, следующее правило сматчит целое число, но поместит в стек не его,
а его утроенное значение:

    def TripleInt = UnsignedInteger ~> (_ * 3)

Тип правила `TripleInt` так и останется `Rule1[Int]`, только вот на стеке будет лежать другое значение.

**Хинт:** Явно указывать тип тип аргументов лямбда-функции есть не очень хорошая идея (по крайней мере, на момент
написания статьи). В компиляторе Scala существует весьма неприятный баг, который не даст вашему коду нормально
скомпилироваться.

С одним аргументом мы разобрались, но что делать, если их несколько? Как поведет себя лямбда? Просто и предсказуемо:
первый параметр соответствует самому верхнему значению на стеке, второй параметр — второму сверху, и так далее.
Так как процедура захвата подвыражений выполняется *справа налево*, то порядок аргументов лямбда-функции соответствует
порядку записи операций захвата:

    def UserWithLambda: Rule2[String, String] = rule {
      (capture(FirstName) ~ Separator ~ capture(LastName)) ~> ((firstName, lastName) => ...)
    }

Благодаря оператору действия мы можем уменьшать количество значений на стеке:

    def UserFirstName = User ~> ((firstName, lastName) => firstName)

В приведённом примере исходный тип правила `User` был `Rule2[String, String]`, применив к нему лямбда-функцию мы
создали новое правило `UserFirstName` с типом `Rule1[String]`.

Лямбда не обязанна принимать *все* параметры со стека, можно вполне ограничиться последними N значениями (помним, что
лямбда забирает аргументы с конца стека):

    def bar = (foo: Rule2[Int, String]) ~> (_.toDouble)
	// bar: Rule2[Int, Double].

Ничего не мешает нам попробовать скормить правилу лямбда-функцию, не имеющую аргументов, с предсказуемым результатом:

    def bar = (foo: Rule2[String, Int]) ~> (() => 42)
	// bar: Rule2[String, Int].

Однако, у Parboiled2 есть более мощные инструменты, такие как возможность вернуть из лямбды на стек сразу группу
значений, используя для этого шейплессовский `HList`:

    def bar = (foo: Rule1[Event]) ~> (e => e::DateTime.now()::"localhost"::HNil)
	// bar: RuleN[Event::DateTime::String::HNil]

Также можно забирать из стека значения, ничего не давая взамен: для этого лямбда всего-навсего должена «возвращать»
тип `Unit`. Типом получившегося правила, как вы наверное догадались, будет `Rule0`:

    def bar = (foo: rule1[String]) ~> (println(_))
    // bar: Rule0

Кроме того, оператор действия предлагает особо сладкий сахар для case-классов:

    case class Person(name: String, age: Int)

    def bar = (foo: Rule2[String, Int]) ~> Person
    // bar: Rule1[Person]

Правда нужно отметить, что компилятор может и не переварить этот сахар, если для case-класса определён companion object.
Тогда придётся добавить лямбду и немного подчёркиваний и записать: `~> (Person(_, _))`.

Сахар для case-классов идеально подходит для построения AST, опытные пользователи могут даже заметить, что в этом случае
он работает совершенно аналогично оператору `~~>` из Parboiled1. Существуют и другие способы применения этой волнистой
стрелочки, но о них вы узнаете не от меня, а из документации. Отмечу только, что оператор `~>` реализуется в коде
Parboiled2 весьма нетривиальным образом, но как бы сложно не выглядело его определение, пользоваться им просто и
интуитивно.


### run

Особая версия оператора действия для любителей острых ощущений. Для программиста во многих отношениях `run` ведёт себя
точно так же, как и `(~>)`, кроме того маленького неудобства, что в случае с `run` компилятор не выводит типы
автоматически и их придётся обозначить явно. Но это делает его очень удобным для создания непроверяемых сайд-эффектов,
например как здесь:

    import sys.process._

    def RuleWithSideEffect = rule {
      capture(ANY.*) ~> run { s: String => "sudo rm -rf /" ! }
    }

Типом результирующего правила будет `Rule0`, а сопоставленная строка вовсе никому не нужна и ни в какой стек значений
не попадёт, что иногда бывает необходимо. Пользователи Parboiled1 наверное заметили, что в `run` ведет себя так же,
как оператор `(~%)`.

**Предупреждение:** При использовании сайд-эффектов, пожалуйста, не заигрывайте со стеком значений. Да, к нему можно
прямой доступ, но по ряду причин этого лучше не делать.


### push

Функция `push` помещает данные на стек значений в случае, если соответствующее ему правило сопоставилось. На практике
мне не приходилось пользоваться им часто, так как большую часть работы может выполнить оператор `(~>)`, но существует
пример, в котором `push` просто блистает:

    sealed trait Bool
    case object True extends Bool
    case object False extends Bool

    def BoolMatch = rule { "true" ~ push(True) | "false" ~ push(False) }

**Хинт:** Хоть это нигде и не помеченно, данное правило следует семантике call-by-name и вычисляется каждый раз, а
значит и его аргумент вычисляется каждый раз. Обычно это не очень хорошо для производительности, поэтому `push` лучше
использовать с константами и только c константами.

Так же как в случае с `run` и `~>`, тип значения, переданного в `push`, определяет содержимое стека и тип создаваемого
правила.


### Вложенные парсеры

ПАШЕ: Глава вообще не написана. Жду ответа от разработчиков
TODO: finisht the article after the response


## Генерация AST

ПАШЕ: Глава еще не написана но краткий план таков
TODO: Взять распознаватель и приделать к нему генерацию AST. Пример проиллюстрировать здесь.
TODO: ++ перевести кусок что ниже

Contrary to the parse tree, which is very closely tied to the grammar by its direct relation to the grammar rules,
the Abstract Syntax Tree you might want to construct for your language heavily depends on your exact project needs.
This is why parboiled takes a very open and flexible approach to supporting it.
There are absolutely no restrictions on the type of your AST nodes. parboiled does provide a number of immutable
and mutable base classes you might choose to use, however, there is nothing that forces you to do so. Take a look at
the org.parboiled.trees package to get started.


## Отчеты об ошибках

Не думаю, что вам захочется работать с парсером, выдающем сообщение «Syntax error» при любых некорректных входных
данных. Parboiled2 способен вполне внятно рассказывать об ошибках, если вы ему в этом поможете.


### Форматирование

Итак, если что-то где-то навернулось, парсер передаст в ваше распоряжение объект типа `ParseError`, который можно
привести в читаемый вид посредством метода `formatError` *самого парсера*:

    val errorMessage = parser formatError error

Если дефолтное форматирование вас по каким-то причинам не устраивает, свои пожелания следует явным образом передать
передать парсеру в опционального параметра метода `formatError`:

    val errorMessage parser.formatError(error, new ErrorFormatter(showTraces = true))

Правда, если вы захотите написать свой `ErrorFormatter`, вам придётся самостоятельно разобраться со структурой
класса `ParseError`, который объявлен в глубине Parboiled таким образом:

    case class ParseError(position: Position, charCount: Int, traces: Seq[RuleTrace]) extends RuntimeException

Также стоит отметить наличие нескольких схем доставки сообщений об ошибке до заказчика: по вашему желанию `ParseError`
может быть представлен не только в виде объекта `Try`, а, например, в виде полиморфного типа или `Either`. Подробнее
можно ознакомиться [в ридми][deliv].

[deliv]: https://github.com/sirthias/parboiled2/blob/master/README.rst#alternative-deliveryschemes


### Тонкая настройка

Прежде всего, всегда есть опция, позволяющая обойти встроенный механизм формирования сообщений об ошибках. Для этого
всего-то нужно использовать правило `fail` с тем сообщением, с каким вы пожелаете:

    def Goldfinger = rule { "talk" | fail("to die") }

Тогда при удобном случае вы получите назад своё сообщение об ошибке, примерно в такой форме:

    `Invalid input 'Bond', expected to die. (line 1, column 1):`


### Именованные правила

Использование их бывает весьма полезным не только в целях отлова ошибок. Использование этого механизма описано ниже
в разделе Best Practices.

### atomic

Parboiled2 создаёт парсер, построенный на PEG. Это означает что он работает на уровне символов, а не строк (как многие
могли подумать), поэтому и ошибки вам будут показываться на символьном уровне. Согласитесь, сообщение вида
«У вас тут X, мы ожидали Y или Z» потребует больше мысленных усилий, чем «У вас тут XX, а мы ожидали увидеть XY
или XZ». Для того, чтобы видеть строки в отчетах об ошибках целиком, придуман маркер `atomiс`, всего-то и нужно
обернуть в него правило:

    def AtomicRuleTest = rule { atomic("foo") | atomic("fob") | atomic("bar") }

Чтобы при лисичках на входе получить

    Invalid input "fox", expected "foo", "fob" or "bar" (line 1, column 1):
    foxes
    ^


## quiet

Когда вариантов для выбора слишком много, не хочется показывать в сообщении об ошибке их все. Например в определенном
месте ваш парсер ожидает множество пробельных символов в совокупности с неким правилом. Для устранения избыточности
в отчете, вы, возможно, захотите умолчать о пробелах. С использованием маркера `quiet` это очень просто:

    def OptionalWhitespaces = rule { quiet(zeroOrMore(anyOf(" \t\n"))) }

Честно признаюсь, ситуаций, поощряющих использования этого правила, я не встречал. Так же, как и `atomic`, оно
подробно [описано в документации][doc-quiet].

[doc-quiet]: https://github.com/sirthias/parboiled2/blob/master/README.rst#the-quiet-marker


## Восстановление после ошибок

Это, практически, единственный эпизод, где Parboiled1 выигрывает. В PB2 дела обстоят не очень хорошо: парсер падает уже
только от вида первой же встреченной им ошибки. Для большинства сценариев это отлично подходит: это, например, не мешает
парсить конфигурационные файлы (не имеет смысла начинать работу с невалидным конфигом), однако разработчикам DSL или
IDE-подобных инструментов такое положение дел будет не по душе. [Маттиас обещает когда-нибудь это исправить][issue-42],
поэтому если вам эта фича очень сильно нужна уже сейчас — пните баг-трекер посильнее, вдруг это ускорит процесс
разработки.

[issue-42]: https://github.com/sirthias/parboiled2/issues/42

В Parboiled1 есть целая [куча ParserRunnerов][runners] на все случаи жизни, посмотрите в сторону `RecoveringParserRunner`,
если вам нужно продолжать парсинг в случае ошибок.

[runners]: https://github.com/sirthias/parboiled/wiki/Parse-Error-Handling


# Тестирование

Разработчики Parboiled используют для тестирования фреймворк [specs2][specs2], который они дополнили своим
вспомогательным классом [TestParserSpec][tps]. Он покажется неудобным тем, кто использует scalatest, но основную
его идею можно и перенять. По секрету от Матиаса, его решение не отличается особенной аккуратностью, так как
полагается на изменяемое соатояние. Возможно, в будущем нас будет ждать что-то похожее на полноценный каркас
для тестирования.

[specs2]: ???
[tps]:    https://goo.gl/v5tCWS

Правила можно тестировать как по отдельности, так и вместе. Лично я предпочитаю писать тесты не на каждое правило,
а проверять только главное правило в заковыристых случаях.

**Кулстори:** Во многих форматах данные, даже стандартизованных, могут встречаться весьма интересные моменты.
Например, в BSD-подобном формате сообщений [RFC 3164][rfc3164] под число месяца *всегда* отводится две позиции,
даже если само число имеет один разряд. Вот пример из самого RFC:

> If the day of the month is less than 10, then it MUST be represented as a space and then the number. For
> example, the 7th day of August would be represented as `"Aug  7"`, with two spaces between the `"g"` and
> the `"7"`.

[rfc3164]: https://www.ietf.org/rfc/rfc3164.txt

Помимо подобного рода «интересных моментов» можно скармливать правилу строки с незакрытыми скобками, недопустимыми
символами, проверять порядок операций со стеком значений.

В тестировании есть ещё одна тонкость, с которой вы сразу же столкнётесь. Предположим, вы хотите оттестировать
следуеющее правило:

    def Decimal = rule { ('+' | '-').? ~ Digit.+ ~ "." ~ Digit.+ }

Для этого скормим правилу заведомо некорректный ввод и будем ждать на выходе ошибку парсинга:

    // Я ещё не видел десятичных дробей с двумя разделителями.
    val p = new MyParser("12.3.456").Decimal.run()
    p.isFailure shouldBe true

Но при прогоне теста окажется, что парсер вернул удачный результат. Почему так? В нашем правиле нет EOI, но если если
мы добавим в него EOI, то испортим все правила, которые используют `Decimal`. Поэтому придётся создать специальное
тестирующее правило при помощи хитрого механизма [мета-правил][metaru]:

    def TestingDecimal = rule { Decimal ~ EOI }
    new MyTest("1.23.456").TestingDecimal.run().isFailure should be true

[metaru]: https://github.com/sirthias/parboiled2/blob/master/README.rst#advanced-techniques


# Недостатки Parboiled2

У любой, даже самой замечательной, библиотеки есть свои недостатки, и тут Parboiled2 не является исключением.

 - Длинные, слишком общие и совершенно непонятные сообщения компилятора об ошибках, в лучших традициях C++. Наглядный
   пример приведен на рисунке ниже (в правиле нечаянно пропущен оператор `~`). Причина связана с выполнением
   продвинутых проверок на типах, которые [обещают убрать][issue-106] в будущих версиях.

![Потеряшки ~](fig-lost-tilda.png)

[issue-106]: https://github.com/sirthias/parboiled2/issues/106

 - Эта проблема относится больше не к Parboiled2, а к scalac. Компилятору сносит крышу, если у лямбды,
   захватывающей значения со стека, явно определены типы аргументов:

        // scalac: «Okay»
        def MyRule = rule { oneOrMore(Visible) ~> (s => "[" + s + "]") }

        // scalac: «No way!»
        def MyRule = rule { oneOrMore(Visible) ~> (s: String => "[" + s + "]") }

 - Многие IDE ещё не научились поддерживать макровыражения, а Parboiled2 весь построен на макровыражениях. Поэтому
   верить подчеркиваниям вашей среды разработки не стоит. Однажды я, забыв об этом, потратил целый день на поиск
   несуществующей ошибки буквально на ровном месте.

 - Отсутствие механизма восстанолвения при неудачном разборе. Проектирущих предметно-ориентированные языки, или же
   тех, кто хочет использовать Parboiled2 в качество фронтэнда к своему компилятору, это сильно разочарует. Но над этим
   уже работают.

 - Я думаю, что многим разработчикам своих небольших IDE, текстовых редакторов хотелось бы видеть более гибкие сообщения
   об ошибках, чем те, что предоставляются сейчас. На данный [момент][issue-96] существует всего два способа повлиять
   на них:
    - именованные правила,
    - именованные вложенные правила.

[issue-96]: https://github.com/sirthias/parboiled2/issues/96

 - Parboiled не приспособлен к лево-рекурсивным грамматикам, поэтому вам придётся доработать вашу грамматику под
   Parboiled.


## Миграция

Миграция — процесс, чаще всего, несложный, но занимает порядочно времени. Поэтмому я постараюсь хотя бы немного
сэкономить вам время и описать основные подводные камни.


### Classpath

Для того чтобы избежать конфликтов с первой версией, Parboiled2 использует classpath `org.parboiled2` (тогда
как classpath для первой версии `org.parboiled`). Мавеновский `groupId`, однако, остался старым: `org.parboiled`.
Благодаря этому можно иметь обе зависимости в одном проекте и осуществлять постепенный переход на новую версию.


### Проверка тестов

Убедитесь в наличии и работоспособности тестов. Они же у вас есть? Нет? Напишите их. В процессе миграции мне
приходилось уточнять некоторые грамматики из-за того, что новый DSL стал мощнее, и тесты при этом часто падали.
С серьезными проблемами, вроде поломки всей грамматики целиком, при миграции я не сталкивался. Может быть кто-то
поделится опытом, если с ним это произошло.


### Код вокруг парсера

Теперь, парсер будет пересоздаваться каждый раз, что не всегда удобно. С PB1 я очень любил создавать парсер один раз,
а потом многократно его переиспользовать, теперь же этот номер не пройдёт, поэтому вам придётся изменить конструктор
парсера и немного переписать использующий его код, и не бойтесь, что это ухудшит производительность.

Однако если вы использовали парсеры на сайдэффектах или генерировали их в рантайме динамически, вам, вероятно,
придётся помучиться: макровыражения в Parboiled2 больно бьют по динамике, давая взамен лучшую производительность.


### Композиция

Подход к композиции элементов парсера не изменился, это хорошая новость для миграторов. Однако `Parser` теперь не
трейт, а абстрактный класс. Трейты (traits) — удобнейшее средство композиции програмных компонентов, в PB1 это позволяло
подмешивать `Parser` в любые модули, смешивая модули между собой. Изменение в пользу абстрактного класса на эту
возможность никак принципиально не повлияло, но теперь для этого нужно использовать self-typed reference:

    trait Numbers { this: Parser =>
      // your code
    }

Также потребуется устранить лишние подмешивания парсера в подмодулях.

Как альтернативный вариант, вы можете сделать из ваших трейтов полноправные парсеры и импортировать из них нужные
правила (как методы) в ваш основной парсер. Я, правда, всё равно предпочитаю использовать для композиции трейты,
потому как нахожу их более наглядными.


### Ревизия велосипедов

В процессе миграции обязательно устройте ревизию своей личной библиотечки примитивных правил: после появления
таких стандартных классов, как `CharPredicate`, она должна заметно похудеть. Нет ничего приятнее, чем выкидывать
ставший ненужным код из проекта.


## Что Parboiled (PEG) не может/не умеет

Большинство статей про комбинаторы парсеров начинается с изматывающих объяснений того, что такое PEG, с чем его есть и
почему его надо бояться. Для того, чтобы парсить конфиги, досконально разбираться в этом не обязательно, но знать об
ограничениях данного типа грамматик всё равно стоит. Итак, Parboiled принципиально не умеет:

 - Разбирать леворекурсивные грамматики. Методы нисходящего разбора (top-down parsers), к коим относятся PEG, не в
   состоянии работать с леворекурсивными грамматиками. В любом случае леворекурсивную грамматику можно
   [адаптировать][lrg-adapt].

[lrg-adapt]: http://bit.ly/1O8aMyR

 - Разбирать грамматики на отступах (indentation-based grammars), например Python или YAML. Не получается это сделать
   из-за того, что сгенерированный парсер является однопроходным, без отдельного лексера. Разбор отступов же
   выполняется на этапе лексического анализа. Для решения данной проблемы существует решение: напишете препроцессор и
   устанавливайте виртуальные маркеры до (INDENT) и после (DEDENT) выхода в отступ. Для Parboiled1 сущестует
   [стандарное решение][pb1-ibg], для Parboiled2 подобную процедуру пока что придётся выполнять самостоятельно.

[pb1-ibg]: https://github.com/sirthias/parboiled/wiki/Indentation-Based-Grammars

 - Использовать потоковый ввод (streaming input). PEG используют поиск с возвратом, он же [бэктрекинг][backtracking].
   Теоретически, этот недостаток можно устранить при помощи буферизации потока, но ничто не мешает написать такую
   грамматику, в которой возможно возврат к самому началу. Поэтому, чтобы эта идея заработала на практике, необходимо
   научиться определять по грамматике границы чанков, между которыми возврат невозможен. Матиас весьма
   [заинтересован][mattias-intrest] в разработке этой фичи, так что возможно ее появление в следующих релизах.

[backtracking]:    https://en.wikipedia.org/wiki/Backtracking
[mattias-intrest]: http://bit.ly/1FNCQj5

# Goodies

Некоторые интересные вещи, которые поддерживаются Parboiled2
 - Разбор строк закодированных в Base64
 - Встраиваемый в парсер StringBuilder, с хэлперами для доступа
 - Возможность динамической диспетчеризации правил (DynamicRuleDispatch)
Есть еще один полезный класс, не затронутый в документации: [CharUtils](http://bit.ly/1NJJ2kd).э
Возможно упасет вас от написания собственного велосипеда


## Мне достался первый Parboiled

Большинство проектов всё ещё написаны на Parboiled1, и вряд-ли что-то изменится резко и кардинально (в энтерпрайзе),
поэтому может быть полезным знать, как научиться мириться с его недостатками.


### Ограничение на 7 правил.

Parboiled1 построен так, что на каждое правило с N элементами имеется по классу, по аналогии со скаловскими кортежами
(tuples): есть `Rule0`, `Rule1`, вплоть до `Rule7`. Этого вполне достаточно, чтобы распарсить сложные языки
программирования, такие как Java, да и вообще не вызывает существенных проблем при разборе древовидных структур.
А вот если нужно извлечь данные из линейной структуры, например, сообщения лога-файла, то в это ограничение очень
несложно упереться. Решается это использованием кортежа вместо одного результирующего правила. Вот пример:

    def Event: Rule1[LogEvent] = rule {
      Header ~ " " ~ UserData ~ " " ~ Message ~~> {
        (header, data, message) => SyslogEvent (
          header._1, header._2, header._3, header._4, header._5, data._1, data._2, message
        )
      }
    }
	  
Пусть выглядит убого, зато проблема решена.


# Best practices
В этом разделе я раскажу о прописных истинах работающих для любого парсер комбинатора, а так же нюансах, специфичных для
Parboiled2.

## Пишите модульные тесты
Одно небольшое неудачное изменение может сломать вам грамматику и обеспечить острую ректальную боль. Это Банальный
совет, которым многие пренебрегают. Парсер не так сложно протестировать, как, скажем IO: Вам не нужны Mock-объекты и
другие ухищрения для этой рутинной, но очень ценной работы. У нас была целая инфраструктура парсеров. И поверьте, первое
что я делал при поиске ошибок - садился и писал тесты, в случае их отсутствия.

## Делайте парсеры маленькими (по возможности)
Разделяйте ваши парсеры, на подпарсеры. Каждый компонент должен делать что-то вполне определенное. Например если вы
парсите LogEvent, у которого опредено поле Timestamp (особенно если этот Timestamp соответствует какому-нибудь Rfc).
Не поленитесь и вынесите его отдельно.

  - Во-первых это уменьшит код вашего основного прасера, и сделает его нагляднее
  - Во-вторых это заметно облегчит тестирование. Вы покроете модульными тестами ваш сабпарсер. А после этого приступите
    к разработке главного парсера

Существуют разные подходы:

 - Разбивать парсер на трейты и использовать self-typed reference (предпочитаю этот способ).
 - Объявлять парсеры как самостоятельные сущности и использовать композицию.
 - Использовать встроенный механизм для создания subParsers


## Делайте правила маленькими
Правила должны быть максимально компактными, но не компактней. Чем меньше ваши правила, тем легче найти ошибку в
грамматике. Это спасало.

## Отправляйте case objects вместо строк в Value stack
Данный совет можно отнести и к оптимизациям, Потому что заставляет парсер работать быстрее.
Отправляйте в Value stack значимые объекты, а не строки. Это сделает ваш парсер быстрее а код нагляднее.

Плохо:

    def logLevel = rule {
      capture("info" | "warning" | "error") ~ ':’
    }
Хорошо:

    def logLevel = rule {
        “info:” ~ push(LogLevel.Info)
      | “warning" ~ push(LogLevel.Warning)
      | “error" ~ push(LogLevel.Error)
    }

## Используйте упрощенный синтаксис для сборки объекта
Этот красивый способ появился еще в Parboiled1. Никакой магии, просот конструктор case classа вызывается неявно.
Главное, чтобы количество и тип аргументов помещаемых на Value Stack совпадали с сигнаторой конструктора case classа.

Плохо:

    def charsAST: Rule1[AST] = rule { capture(Characters) ~> ((s: String) => AText(s)) }

Хорошо:

    def charsAST = rule { capture(Characters) ~> AText }

## Именнованные правила (named rules)
Именованные правила заметно упрощают жизнь при получении отчетов об ошибках, так как дают возможность вместо
бестолкового имени правила использовать псевдоним. Или же помечать правила определенным тегом - "Йоу! Это выражение"
или "аффектит стек". В люобм случае знать о данной функции будет полезно.

Многие пользователи Parboiled1 уже полюбили эту фичу. Например разработчики Neo4J, использующие Parboiled для
разбора языка [Cypher](http://neo4j.com/docs/2.2.3/cypher-introduction.html).
Как это выглядит в Parboiled1:

    def Header: Rule1[Header] = rule("I am header") { ... }
В Parboiled2:

    def Header: Rule1[Header] = namedRule("header is here") { ... }
Так же есть возможность давать имена вложенным правилам:

    def UserName = rule { Prefix ~ oneOrMore(NameChar).named("username") ~ PostFix }


# Оптимизации
Главное при выполнении оптимизаций - своевременность. Это то с чем не стоит спешить.
## Развертка n.times для n <= 4
Вы можете выиграть в производительности если вместо правила "times" для маленьких n

    rule { 4 times CharPredicate.Digit }
будете использовать правило последовательности "sequence" (оно же тильда)

    import CharPredicate.Digit
    rule { Digit ~ Digit ~ Digit ~ Digit }
Это связано в существующей на момент публикации данной статьи
[проблемой](https://github.com/sirthias/parboiled2/issues/101).

## Ускорение операций со стеком для nTimes
Использование подобной оптимизации при извлечении чисел со стека тоже позволит вам выжать немножко производительности

    def digit4 = rule {
      Digit ~ Digit ~ Digit ~ Digit ~ push(#(charAt(-4))*1000 + #(charAt(-3))*100 + #(charAt(-2))*10 + #(lastChar))
    }

## О предикатах
### Не пересоздавайте CharPredicate каждый раз
CharPredicate это и case class и companion object с набором вспомогательных методов. Сущность вполне самостоятельная
и может использоваться за пределами правил. Это нормально каждый раз когда используете предопределенный предикат,
например CharPredicate.Digit внутри блока правила (rule). Однако создавать свой CharPredicate внутри rule не стоит.
Данный предикат будет создаваться каждый раз. Это драматически уменьшит производительность вашего парсера. Поэтому
не создавайте их каждый раз, а определите единожды как val внутри вашего парсера, а еще лучше отправить это в объект
компаньен вашего парсера:

    val Uppercase = CharPredicate.from(_.isUpper)

### Семантические предикаты
Достаточно подробно описаны в документации. Особенность данных правил в том что они не взаимодействую со стеком
значений. И самое главное что вы должны знать об этих правилах:

> При использовании сематрических предикатов, парсер не совершает прогресса: т.е. не перемещает свой курсор на следующий
символ. Поэтому при неумелом исползовании ваш парсер может зациклить.

Помните пример c объявлением символьного предиката для символов верхнего регистра? Вы можете сделать тоже
самое использую семантический предикат:

    def JavaUpperCase = rule { oneOrMore(test(currentChar.isUpper) ~ ANY) }

>>Используйте ANY там где хотели видеть CharPredicate.All

CharPredicate.All работает медленно для больших диапазонов символов. ANY работает быстрее. Воспользуйтесь этим

### Использование инветирующего предиката
Предположим вам нужно noneOf, но только для одного символа. Представьте, что ваш парсер должен термирироваться при виде
символа перевода строки (unix). Конечно сделать это можно используя noneOf, но инвертирующий предикат будет быстрее:

    def foo = rule { capture(zeroOrMore(!'\n')) }

И данный, замечательно выглядящий пример зациклит, потому что парсер не будет совершать прогресса. чтобы парсер двигался
необходимо правило передвигающее курсор парсера, но при этом не изменяющее стек. Делается это так:

    def foo = rule { capture(zeroOrMore( !'\n' ~ ANY )) }

теперь под foo поглотит абсолютно все, кроме EOI и `\n`.


# Заключение
Спасибо что дочитали этот длиннопост до конца, или хотя бы пролистали. В этой статье я попытался рассказать вам про
самый прогрессивный и перспективный инструмент парсинга существующий для языка scala. Сделал небольшой туториал, и
рассказал о тех проблемах с какими пришлось столкнуться на практике. Надеюсь что что эта статья в худшем случае окажется
для вас полезной, а в лучшем - станет руководстком к действию.


Использованные источники
========================
 - [Юзергруппа](https://groups.google.com/forum/#!topic/parboiled-user/Ygb_M6XU5P8) посвященная Parboiled2
   Здесь вы можете задать все интересующие вас вопросы. Вам помогут.
 - Презентация Александра Мыльцева [Видео](http://www.youtube.com/watch?v=qZg4D62K4aQ)
 - [Слайды](http://myltsev.name/ScalaDays2014/#/) к презентации Александра [ENG]
 - Официальная [документация](https://github.com/sirthias/parboiled2/blob/master/README.rst)
 - [Примеры](https://github.com/sirthias/parboiled2/tree/master/examples/src/main/scala/org/parboiled2/examples)
   исходного кода
